var store = [{
        "title": "Jekyll blog test",
        "excerpt":"title  content —– ‘’’ code ‘’’  ","categories": ["random"],
        "tags": [],
        "url": "https://jc5201.github.io/random/test/",
        "teaser":null},{
        "title": "GPT-3를 보면서 생각하는 source code generation",
        "excerpt":"최근 OpenAI에서 GPT-3(Generative Pre-trained Transformer 3) 라는 API 와 논문을 공개했다. https://openai.com/blog/openai-api/ https://arxiv.org/pdf/2005.14165.pdf GPT-3 가 뭔지 처음 듣는 사람은 아래 데모 영상들을 보고 오자. https://machinelearningtokyo.com/2020/07/26/10-cool-gpt-3-demos/ GPT-3 는 openAI에서 돈이 필요해서 유료로 판다고 한다. 뭐 모델이 좀 많이 커서 앵간한 회사들은 돌리지도 못할 거라고 하긴 한다. 일단 성능이 상당히 좋아서 관심을...","categories": ["random"],
        "tags": [],
        "url": "https://jc5201.github.io/random/gpt-3-source-code-generation/",
        "teaser":null},{
        "title": "ubuntu GUI setting",
        "excerpt":"사용 환경 : virtualbox + ubuntu server 20.04 + i3 + st-luke i3 순정 i3를 쓸 거면 apt 사용해서 그냥 설치하면 된다. sudo apt install i3 난 i3-gaps를 쓸 것이기 때문에 i3-gaps를 빌드해서 설치했고, 다음 페이지를 참고했다. https://dymaxionkim.github.io/beautiful-jekyll/2019-06-20-rounded-i3-gaps-on-ubuntu/ https://gist.github.com/boreycutts/6417980039760d9d9dac0dd2148d4783 i3 설정은 ~/.config/i3/config 에서 하면 된다. st-luke 디폴트로 깔려있는 터미널 쓰기...","categories": ["setting"],
        "tags": [],
        "url": "https://jc5201.github.io/setting/i3-setting/",
        "teaser":null},{
        "title": "Unsupervised Cross-Domain Singing Voice Conversion",
        "excerpt":"intro facebook ai 쪽 논문이고, timbre transfer 관련이라고 보면 될 것 같다. 처음에 학습 시킬 때 speaker identity에 따라 다른 timbre를 표현하게 학습시키고, 이후에 다른 목소리를 표현하고 싶으면 그 목소리와 비슷한 speaker identity를 찾는 모델이다. speaker identity를 찾는 과정은 speech 데이터에서도 찾을 수 있고, 상대적으로 적은 데이터로 할 수 있다....","categories": ["paper - audio"],
        "tags": [],
        "url": "https://jc5201.github.io/paper%20-%20audio/paper-Unsupervised-Cross-Domain-Singing-Voice-Conversion/",
        "teaser":null},{
        "title": "Music Source Separation in the waveform domain",
        "excerpt":"intro facebook ai 쪽에 있는 defossez라는 아저씨 논문이다. Demucs 라고 다른 논문들에서 baseline으로 주로 제시되는 모델 중 하나인데 publish된 적은 없는 것 같다. 데모부터 들어보면 상당히 괜찮은 결과를 보여준다. https://ai.honu.io/papers/demucs/index.html 작년에 wave u net 가지고 씨름하지 말고 이 모델을 바로 시도했으면 어땠을까 싶다. content 푸는 문제는 전형적인 music source separation...","categories": ["paper - audio"],
        "tags": [],
        "url": "https://jc5201.github.io/paper%20-%20audio/paper-demucs/",
        "teaser":null}]
